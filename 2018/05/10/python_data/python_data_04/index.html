<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>Python网络爬虫实践－腾讯新闻 | KingDom's Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="靳中的博客,靳中,kingdom的博客,java,前端博客, 前端, 程序员, 前端开发, 全栈开发, node.js, javascript"><meta name="description" content="日常学习与技术交流的个人博客"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><meta name="baidu-site-verification" content="eolBgn9cYc"><link rel="canonical" href="http://baofengketang.com/2018/05/10/python_data/python_data_04/index.html"><link rel="icon" type="image/png" href="http://p6wdo7p1v.bkt.clouddn.com/favicon.ico" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="KingDom"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b69e8a5da7ae592872f8dabee653c8a2";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(http://p6wdo7p1v.bkt.clouddn.com/loader.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="KingDom" alt="KingDom"><img src="http://p6wdo7p1v.bkt.clouddn.com/CreateZiTi-4%28%E5%B7%B2%E5%8E%BB%E5%BA%95%29.png" alt="KingDom"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="http://p6wdo7p1v.bkt.clouddn.com/1525908359.png" alt="Python网络爬虫实践－腾讯新闻"></div><header class="post__info"><h1 class="post__title">Python网络爬虫实践－腾讯新闻</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="http://www.baofengketang.com">Kingdom</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2018-05-10</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/爬虫/">爬虫</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><div class="toc"><ul><li><a href="#pa-chong-shi-jian-teng-xun-xin-wen">爬虫实践－腾讯新闻</a><ul><li><a href="#wang-zhan-fen-xi">网站分析</a></li><li><a href="#ding-zhi-qing-qiu-tou">定制请求头</a></li><li><a href="#chuan-di-url-can-shu">传递url参数</a></li><li><a href="#fa-song-post-qing-qiu">发送POST请求</a></li><li><a href="#chao-shi">超时</a></li><li><a href="#huo-qu-xiang-ying-de-nei-rong">获取响应的内容</a></li><li><a href="#kai-shi-pa-qu-shu-ju">开始爬取数据</a></li></ul></li></ul></div><h1><span id="pa-chong-shi-jian-teng-xun-xin-wen">爬虫实践－腾讯新闻</span><a href="#pa-chong-shi-jian-teng-xun-xin-wen" class="header-anchor">#</a></h1><h2><span id="wang-zhan-fen-xi">网站分析</span><a href="#wang-zhan-fen-xi" class="header-anchor">#</a></h2><p>打开腾讯新闻：<a href="http://news.qq.com/" target="_blank" rel="noopener">http://news.qq.com/</a></p><p><img src="http://p6wdo7p1v.bkt.clouddn.com/1525936909.png?imageMogr2/thumbnail/!70p" alt=""></p><h2><span id="ding-zhi-qing-qiu-tou">定制请求头</span><a href="#ding-zhi-qing-qiu-tou" class="header-anchor">#</a></h2><p>观察一下该网站的请求头</p><p><img src="http://p6wdo7p1v.bkt.clouddn.com/1525937054.png?imageMogr2/thumbnail/!70p" alt=""></p><p>请求头Headers提供了关于请求、响应或者其它发送实体的信息，对于爬虫而言，请求头十分重要，如果没有请求头或者请求头和实际网页不一致，就可能无法返回正确的结果</p><p>Request并不会基于定制的请求头Header的具体情况改变自己的行为，只是在最后的请求中，所有的请求头信息都会被传递进去</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:59.0) Gecko/20100101 Firefox/59.0"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="chuan-di-url-can-shu">传递url参数</span><a href="#chuan-di-url-can-shu" class="header-anchor">#</a></h2><p>为了请求特定的数据，我们需要在URL的查询字符串中加入某些数据，如果你是自己构建的url，那么数据一般会跟在一个问好后面，并且以键/值的形式放在URL中,比如 url?key1=value1</p><p>在Request中，我们可以将这些参数保存在字典中，用params构建至url中,例如传递key1＝value1和key2=value2</p><p>到url上可以这么编写</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:59.0) Gecko/20100101 Firefox/59.0"</span></span><br><span class="line">&#125;</span><br><span class="line">key_dict=&#123;<span class="string">"key1"</span>:<span class="string">"value1"</span>,<span class="string">"key2"</span>:<span class="string">"value2"</span>&#125;</span><br><span class="line">url=<span class="string">"http://news.qq.com/"</span></span><br><span class="line">r=requests.get(url,headers=headers,params=key_dict)</span><br><span class="line">print(<span class="string">"响应状态码"</span>,r.status_code)</span><br></pre></td></tr></table></figure><h2><span id="fa-song-post-qing-qiu">发送POST请求</span><a href="#fa-song-post-qing-qiu" class="header-anchor">#</a></h2><p>除了发送get请求外，有时候还需要发送一些编码为表单形式的数据，比如登陆的时候为POST,因为如果使用GET请求，密码显示在URL上，这是非常不安全的，如果实现post请求，只需要简单的传递一个字典给Requests中的data参数，这个字典就会在发出请求的时候自动编码为表单形式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:59.0) Gecko/20100101 Firefox/59.0"</span></span><br><span class="line">&#125;</span><br><span class="line">key_dict=&#123;<span class="string">"key1"</span>:<span class="string">"value1"</span>,<span class="string">"key2"</span>:<span class="string">"value2"</span>&#125;</span><br><span class="line">url=<span class="string">"http://news.qq.com/"</span></span><br><span class="line">r=requests.post(url,headers=headers,data=key_dict)</span><br><span class="line">print(<span class="string">"响应状态码"</span>,r.status_code)</span><br></pre></td></tr></table></figure><h2><span id="chao-shi">超时</span><a href="#chao-shi" class="header-anchor">#</a></h2><p>有的时候爬虫会遇到服务器长时间不返回，这个时候爬虫就会一直等待，造成爬虫没有顺利的进行，因此可以在requests的timeout参数设定的秒数结束之后停止等待响应，意思就是，服务器在timeout秒内没有应答，就返回异常</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:59.0) Gecko/20100101 Firefox/59.0"</span></span><br><span class="line">&#125;</span><br><span class="line">key_dict=&#123;<span class="string">"key1"</span>:<span class="string">"value1"</span>,<span class="string">"key2"</span>:<span class="string">"value2"</span>&#125;</span><br><span class="line">url=<span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">r=requests.get(url,headers=headers,timeout=<span class="number">0.001</span>)</span><br><span class="line">print(<span class="string">"响应状态码"</span>,r.status_code)</span><br></pre></td></tr></table></figure><p>运行时报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host=&apos;news.qq.com&apos;, port=443): Max retries exceeded with url: /top250 (Caused by ConnectTimeoutError(&lt;urllib3.connection.VerifiedHTTPSConnection object at 0x1086c3080&gt;, &apos;Connection to movie.douban.com timed out. (connect timeout=0.001)&apos;))</span><br></pre></td></tr></table></figure><p>一般情况我们将这个值设置为20秒</p><h2><span id="huo-qu-xiang-ying-de-nei-rong">获取响应的内容</span><a href="#huo-qu-xiang-ying-de-nei-rong" class="header-anchor">#</a></h2><blockquote><p>在request中，最常用的功能就是获取某个网页的内容</p><p>r=requests.get(“url”)：方法返回一个response对象</p><p>通过这个response对象我们可以获取我们想要的信息</p><p>r.text:是服务器响应的内容，会自动根据响应头部的字符编码进行解码</p><p>r.encoding:是服务器内容使用的文本编码</p><p>r.status_code:用于监测响应的状态码，如200，404等</p><p>r.content:是字节码的响应体，会自动解码gzip和deflate编码的数据</p><p>r.json():是requests中内置的josn解码器</p></blockquote><h2><span id="kai-shi-pa-qu-shu-ju">开始爬取数据</span><a href="#kai-shi-pa-qu-shu-ju" class="header-anchor">#</a></h2><p>我们需要爬取这个页面的每个新闻的标题，鼠标右击一条新闻标题，选择“审查元素”<img src="http://p6wdo7p1v.bkt.clouddn.com/1525937309.png?imageMogr2/thumbnail/!70p" alt=""></p><p>在次审查一下另外一个元素</p><p><img src="http://p6wdo7p1v.bkt.clouddn.com/1525937389.png?imageMogr2/thumbnail/!70p" alt=""></p><p>发现有共性，接下来我们就可以采用爬虫来进行爬取我们需要的标题与链接内容了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding=UTF-8</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:59.0) Gecko/20100101 Firefox/59.0"</span></span><br><span class="line">&#125;</span><br><span class="line">url = <span class="string">"http://news.qq.com"</span></span><br><span class="line">r=requests.get(url,headers=headers)</span><br><span class="line">data = r.text</span><br><span class="line">soup =BeautifulSoup(data,<span class="string">"html.parser"</span>)</span><br><span class="line">news=soup.select(<span class="string">"div.text em.l24 a.linkto"</span>)</span><br><span class="line">f=open(<span class="string">"news.txt"</span>,<span class="string">"w"</span>)</span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> news:</span><br><span class="line">    title=n.get_text();</span><br><span class="line">    link=n.get(<span class="string">"href"</span>)</span><br><span class="line">    data=&#123;</span><br><span class="line">        <span class="string">"标题"</span>:title,</span><br><span class="line">        <span class="string">"链接"</span>:link</span><br><span class="line">    &#125;</span><br><span class="line">    print(data)</span><br><span class="line">    f.write(<span class="string">"%s:%s"</span>%(title,link)+<span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure><div class="post-announce">感谢您的阅读，本文由 <a href="http://www.baofengketang.com">Kingdom</a> 原创提供。如若转载，请注明出处：Kingdom（<a href="http://www.baofengketang.com">http://www.baofengketang.com</a>）</div><div class="post__prevs"><div class="post__prev"><a href="/2018/05/10/python_data/python_data_03/" title="Python爬虫入门"><i class="iconfont icon-prev"></i>Python爬虫入门</a></div><div class="post__prev post__prev--right"><a href="/2018/05/10/python_data/python_data_05/" title="Python爬虫实践－今日头条（获取js动态内容）">Python爬虫实践－今日头条（获取js动态内容）<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">日常学习与技术交流的个人博客</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/项目构建/">项目构建</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/诗词/">诗词</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/爬虫/">爬虫</a><span class="block-list-count">6</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/vim/">vim</a><span class="block-list-count">2</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/redis/">redis</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/mybatis/">mybatis</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/linux/">linux</a><span class="block-list-count">6</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/java/">java</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/hexo/">hexo</a><span class="block-list-count">2</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Python/">Python</a><span class="block-list-count">13</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2018/05/17/redis/redis_01/" title="redis实战"><div class="item__cover"><img src="http://p6wdo7p1v.bkt.clouddn.com/1526535093.png" alt="redis实战"></div><div class="item__info"><h3 class="item__title">redis实战</h3><span class="item__text">2018-05-17</span></div></a></li><li class="latest-post-item"><a href="/2018/05/13/hexo/hexo_02/" title="使用hexo搭建个人博客"><div class="item__cover"><img src="http://p6wdo7p1v.bkt.clouddn.com/1526203720.png" alt="使用hexo搭建个人博客"></div><div class="item__info"><h3 class="item__title">使用hexo搭建个人博客</h3><span class="item__text">2018-05-13</span></div></a></li><li class="latest-post-item"><a href="/2018/05/13/hexo/hexo_01/" title="使用hexo搭建个人博客"><div class="item__cover"><img src="http://p6wdo7p1v.bkt.clouddn.com/1526203720.png" alt="使用hexo搭建个人博客"></div><div class="item__info"><h3 class="item__title">使用hexo搭建个人博客</h3><span class="item__text">2018-05-13</span></div></a></li><li class="latest-post-item"><a href="/2018/05/13/python_base/python_13/" title="Python基础(十三)"><div class="item__cover"><img src="http://p6wdo7p1v.bkt.clouddn.com/1524200671.png" alt="Python基础(十三)"></div><div class="item__info"><h3 class="item__title">Python基础(十三)</h3><span class="item__text">2018-05-13</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/hexo/">hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/java/">java</a></li><li class="tag-item"><a class="tag-link" href="/tags/linux/">linux</a></li><li class="tag-item"><a class="tag-link" href="/tags/maven/">maven</a></li><li class="tag-item"><a class="tag-link" href="/tags/mybatis/">mybatis</a></li><li class="tag-item"><a class="tag-link" href="/tags/redis/">redis</a></li><li class="tag-item"><a class="tag-link" href="/tags/vim/">vim</a></li><li class="tag-item"><a class="tag-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-item"><a class="tag-link" href="/tags/爬虫/">爬虫</a></li><li class="tag-item"><a class="tag-link" href="/tags/编辑器/">编辑器</a></li><li class="tag-item"><a class="tag-link" href="/tags/诗词/">诗词</a></li><li class="tag-item"><a class="tag-link" href="/tags/项目构建/">项目构建</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站主要用于分享日常学习、生活及工作的一些心得总结</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Nanjing, Jiangsu Province, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>183588002@qq.com</span></li></ul></div></div><div class="footer-top__item footer__image"><img src="http://p6wdo7p1v.bkt.clouddn.com/weixin.jpg" alt="logo" title="KingDom"></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://www.cnblogs.com" title="开发者的网上家园" target="_blank">博客圆</a></li><li class="list-item"><a href="https://www.csdn.net" title="专业技术社区" target="_blank">csdn</a></li><li class="list-item"><a href="" title="敬请期待" target="_blank">敬请期待</a></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">构建工具</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://hexo.io/" title="Blog Framework" target="_blank">Hexo</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>.</p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://www.baofengketang.com" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="mailto:183588002@qq.com" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="https://www.zhihu.com/people/kingdom-31-2/pins" target="_blank" title="知乎"><i class="iconfont icon-zhihu"></i></a></li></ul></div></section><div id="SOHUCS"></div><script type="text/javascript">!function(){var t,e,n,a,c="cytCwnI0Q",o="prod_23cc6d0e33f4f5b0679dcf80ddcae682";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id='+c+"&conf="+o+'"><\/script>');else{t="https://changyan.sohu.com/upload/changyan.js",e=function(){window.changyan.api.config({appid:c,conf:o})},n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,(a=document.createElement("script")).setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}}()</script></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script>!--PC和WAP自适应版--><div id="SOHUCS"></div><script type="text/javascript">!function(){var t,e,n,a,c="cytCwnI0Q",o="prod_23cc6d0e33f4f5b0679dcf80ddcae682";if((window.innerWidth||document.documentElement.clientWidth)<960)window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id='+c+"&conf="+o+'"><\/script>');else{t="https://changyan.sohu.com/upload/changyan.js",e=function(){window.changyan.api.config({appid:c,conf:o})},n=document.getElementsByTagName("head")[0]||document.head||document.documentElement,(a=document.createElement("script")).setAttribute("type","text/javascript"),a.setAttribute("charset","UTF-8"),a.setAttribute("src",t),"function"==typeof e&&(window.attachEvent?a.onreadystatechange=function(){var t=a.readyState;"loaded"!==t&&"complete"!==t||(a.onreadystatechange=null,e())}:a.onload=e),n.appendChild(a)}}()</script><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",model:{jsonPath:"/live2dw/assets/koharu.model.json"},display:{position:"left",width:60,height:120,hOffset:0,vOffset:-20},mobile:{show:!0,scale:.5},react:{opacityDefault:.8,opacityOnHover:.2}})</script></body></html>